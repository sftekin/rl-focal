{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-2-13b-chat-hf', 'Llama-2-70b-chat-hf', 'Mistral-7B-Instruct-v0.2', 'Mixtral-8x7B-Instruct-v0.1', 'gemma-2b', 'gemma-7b', 'phi-2']\n",
      "Truncating the space size\n",
      "Truncating the space size\n",
      "Llama-2-13b-chat-hf 0.41189746896662904\n",
      "Llama-2-70b-chat-hf 0.5661776559729164\n",
      "Mistral-7B-Instruct-v0.2 0.5779461550862486\n",
      "Mixtral-8x7B-Instruct-v0.1 0.6886990166048687\n",
      "gemma-2b 0.24214089956472676\n",
      "gemma-7b 0.745445752055457\n",
      "phi-2 0.7173948089634048\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_generator.data_loader import DataCreator\n",
    "\n",
    "model_names = ['Llama-2-13b-chat-hf', 'Llama-2-70b-chat-hf', 'Mistral-7B-Instruct-v0.2',\n",
    "                'Mixtral-8x7B-Instruct-v0.1', 'gemma-2b', 'gemma-7b', 'phi-2']\n",
    "task_name = \"gsm8k\"\n",
    "\n",
    "datacreator = DataCreator(task_name, model_names=model_names, task_type=\"lang\")\n",
    "\n",
    "for i, (train_data, test_data, num_models, ds_name) in enumerate(datacreator.load()):\n",
    "    break\n",
    "\n",
    "labels = train_data[:, -1]\n",
    "model_preds = []\n",
    "for arr_spl in np.split(train_data[:, :-1], len(model_names), axis=1):\n",
    "    model_preds.append(arr_spl.argmax(1))\n",
    "model_preds = np.array(model_preds).T\n",
    "\n",
    "for i, mn in enumerate(model_names):\n",
    "    print(mn, np.mean(labels == model_preds[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.24456958970234\n"
     ]
    }
   ],
   "source": [
    "comb_idx = [3, 5, 6]\n",
    "\n",
    "labels = test_data[:, -1]\n",
    "model_preds = []\n",
    "for arr_spl in np.split(test_data[:, :-1], len(model_names), axis=1):\n",
    "    model_preds.append(arr_spl.argmax(1))\n",
    "model_preds = np.array(model_preds).T\n",
    "\n",
    "model_preds = model_preds[:, comb_idx]\n",
    "preds = []\n",
    "for i in range(len(model_preds)):\n",
    "    if i == 0:\n",
    "        rand_idx = np.random.randint(0, len(comb_idx))\n",
    "        preds.append(model_preds[i, rand_idx])\n",
    "    else:\n",
    "        correct_ids = model_preds[i-1] == labels[i-1]\n",
    "        if sum(correct_ids) != 0:\n",
    "            next_decision = np.random.randint(sum(correct_ids))\n",
    "            preds.append(model_preds[i, correct_ids][next_decision])\n",
    "        else:\n",
    "            rand_idx = np.random.randint(0, len(comb_idx))\n",
    "            preds.append(model_preds[i, rand_idx])\n",
    "\n",
    "preds = np.array(preds)\n",
    "print(np.mean(labels==preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 6., 0., 0.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 1, 0, ..., 3, 0, 0],\n",
       "       [2, 0, 0, ..., 2, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 7, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 4, 0, 0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 1, 1],\n",
       "       [0, 0, 1, ..., 0, 1, 1],\n",
       "       [0, 1, 1, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 1, 1],\n",
       "       [0, 1, 1, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_models = len(model_names)\n",
    "error_arr = (model_preds ==  np.repeat(labels[:, None], num_models, axis=1)).astype(int)\n",
    "error_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.ens_env import HistData\n",
    "from env.ens_metrics import calc_div_acc\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"prob_arr\": train_data[:, :-1],\n",
    "    \"error_arr\": error_arr,\n",
    "    \"pred_arr\": model_preds,\n",
    "    \"label_arr\": labels,\n",
    "}\n",
    "\n",
    "hist_data = HistData(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "scores = []\n",
    "ens_sizes = np.arange(2, num_models + 1)\n",
    "for j, ens_size in enumerate(ens_sizes):\n",
    "    print(ens_size)\n",
    "    combinations = list(itertools.combinations(range(num_models), ens_size))\n",
    "    for comb in combinations:\n",
    "        comb_idx = np.zeros(num_models, dtype=int)\n",
    "        comb_idx[list(comb)] = 1\n",
    "        scores.append(calc_div_acc(comb_idx, hist_data))\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.diversity_stats import calc_stat_matrices\n",
    "\n",
    "error_dict = {model_names[i]:error_arr[:, i] for i in range(num_models)}\n",
    "stats_matrices = calc_stat_matrices(error_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q_statistics', 'correlation_co-efficiency', 'binary_disagreement', 'kappa_statistics'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_matrices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Llama-2-13b-chat-hf</th>\n",
       "      <th>Llama-2-70b-chat-hf</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>gemma-2b</th>\n",
       "      <th>gemma-7b</th>\n",
       "      <th>phi-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-2-13b-chat-hf</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324198</td>\n",
       "      <td>0.332420</td>\n",
       "      <td>0.438014</td>\n",
       "      <td>0.316782</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.388360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-2-70b-chat-hf</th>\n",
       "      <td>0.324198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313236</td>\n",
       "      <td>0.335966</td>\n",
       "      <td>0.420764</td>\n",
       "      <td>0.314042</td>\n",
       "      <td>0.315976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.332420</td>\n",
       "      <td>0.313236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337417</td>\n",
       "      <td>0.417056</td>\n",
       "      <td>0.278414</td>\n",
       "      <td>0.289699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.438014</td>\n",
       "      <td>0.335966</td>\n",
       "      <td>0.337417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531033</td>\n",
       "      <td>0.279220</td>\n",
       "      <td>0.287280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2b</th>\n",
       "      <td>0.316782</td>\n",
       "      <td>0.420764</td>\n",
       "      <td>0.417056</td>\n",
       "      <td>0.531033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530066</td>\n",
       "      <td>0.517492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.314042</td>\n",
       "      <td>0.278414</td>\n",
       "      <td>0.279220</td>\n",
       "      <td>0.530066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi-2</th>\n",
       "      <td>0.388360</td>\n",
       "      <td>0.315976</td>\n",
       "      <td>0.289699</td>\n",
       "      <td>0.287280</td>\n",
       "      <td>0.517492</td>\n",
       "      <td>0.208931</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Llama-2-13b-chat-hf  Llama-2-70b-chat-hf  \\\n",
       "Llama-2-13b-chat-hf                    0.000000             0.324198   \n",
       "Llama-2-70b-chat-hf                    0.324198             0.000000   \n",
       "Mistral-7B-Instruct-v0.2               0.332420             0.313236   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.438014             0.335966   \n",
       "gemma-2b                               0.316782             0.420764   \n",
       "gemma-7b                               0.399000             0.314042   \n",
       "phi-2                                  0.388360             0.315976   \n",
       "\n",
       "                            Mistral-7B-Instruct-v0.2  \\\n",
       "Llama-2-13b-chat-hf                         0.332420   \n",
       "Llama-2-70b-chat-hf                         0.313236   \n",
       "Mistral-7B-Instruct-v0.2                    0.000000   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.337417   \n",
       "gemma-2b                                    0.417056   \n",
       "gemma-7b                                    0.278414   \n",
       "phi-2                                       0.289699   \n",
       "\n",
       "                            Mixtral-8x7B-Instruct-v0.1  gemma-2b  gemma-7b  \\\n",
       "Llama-2-13b-chat-hf                           0.438014  0.316782  0.399000   \n",
       "Llama-2-70b-chat-hf                           0.335966  0.420764  0.314042   \n",
       "Mistral-7B-Instruct-v0.2                      0.337417  0.417056  0.278414   \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.000000  0.531033  0.279220   \n",
       "gemma-2b                                      0.531033  0.000000  0.530066   \n",
       "gemma-7b                                      0.279220  0.530066  0.000000   \n",
       "phi-2                                         0.287280  0.517492  0.208931   \n",
       "\n",
       "                               phi-2  \n",
       "Llama-2-13b-chat-hf         0.388360  \n",
       "Llama-2-70b-chat-hf         0.315976  \n",
       "Mistral-7B-Instruct-v0.2    0.289699  \n",
       "Mixtral-8x7B-Instruct-v0.1  0.287280  \n",
       "gemma-2b                    0.517492  \n",
       "gemma-7b                    0.208931  \n",
       "phi-2                       0.000000  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_matrices[\"binary_disagreement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(0, 1) 0.32419796872481055\n",
      "(0, 2) 0.3324197968724811\n",
      "(0, 3) 0.4380138642592294\n",
      "(0, 4) 0.31678220216024505\n",
      "(0, 5) 0.39900048363694984\n",
      "(0, 6) 0.38836047073996455\n",
      "(1, 2) 0.31323553119458325\n",
      "(1, 3) 0.3359664678381428\n",
      "(1, 4) 0.42076414638078347\n",
      "(1, 5) 0.3140415927776882\n",
      "(1, 6) 0.3159761405771401\n",
      "(2, 3) 0.33741737868773175\n",
      "(2, 4) 0.41705626309850075\n",
      "(2, 5) 0.27841367080444945\n",
      "(2, 6) 0.28969853296791875\n",
      "(3, 4) 0.5310333709495405\n",
      "(3, 5) 0.27921973238755443\n",
      "(3, 6) 0.2872803482186039\n",
      "(4, 5) 0.5300660970498146\n",
      "(4, 6) 0.5174915363533774\n",
      "(5, 6) 0.20893116234080283\n",
      "3\n",
      "(0, 1, 2) 0.32328443226395825\n",
      "(0, 1, 3) 0.3660594336073943\n",
      "(0, 1, 4) 0.3539147724219463\n",
      "(0, 1, 5) 0.34574668171314954\n",
      "(0, 1, 6) 0.3428448600139717\n",
      "(0, 2, 3) 0.36928367993981404\n",
      "(0, 2, 4) 0.35541942071040894\n",
      "(0, 2, 5) 0.33661131710462683\n",
      "(0, 2, 6) 0.33682626686012146\n",
      "(0, 3, 4) 0.4286098124563383\n",
      "(0, 3, 5) 0.3720780267612445\n",
      "(0, 3, 6) 0.37121822773926594\n",
      "(0, 4, 5) 0.4152829276156698\n",
      "(0, 4, 6) 0.4075447364178624\n",
      "(0, 5, 6) 0.3320973722392391\n",
      "(1, 2, 3) 0.3288731259068192\n",
      "(1, 2, 4) 0.3836853135579559\n",
      "(1, 2, 5) 0.3018969315922403\n",
      "(1, 2, 6) 0.3063034015798807\n",
      "(1, 3, 4) 0.4292546617228223\n",
      "(1, 3, 5) 0.30974259766779516\n",
      "(1, 3, 6) 0.3130743188779623\n",
      "(1, 4, 5) 0.4216239454027621\n",
      "(1, 4, 6) 0.41807727443710035\n",
      "(1, 5, 6) 0.2796496318985437\n",
      "(2, 3, 4) 0.428502337578591\n",
      "(2, 3, 5) 0.2983502606265786\n",
      "(2, 3, 6) 0.3047987532914181\n",
      "(2, 4, 5) 0.40851201031758827\n",
      "(2, 4, 6) 0.408082110806599\n",
      "(2, 5, 6) 0.259014455371057\n",
      "(3, 4, 5) 0.4467730667956365\n",
      "(3, 4, 6) 0.44526841850717397\n",
      "(3, 5, 6) 0.2584770809823204\n",
      "(4, 5, 6) 0.41882959858133156\n",
      "4\n",
      "(0, 1, 2, 3) 0.3468751679294964\n",
      "(0, 1, 2, 4) 0.35407598473856733\n",
      "(0, 1, 2, 5) 0.3268848406684937\n",
      "(0, 1, 2, 6) 0.3273147401794831\n",
      "(0, 1, 3, 4) 0.3944596700521253\n",
      "(0, 1, 3, 5) 0.3484066849373959\n",
      "(0, 1, 3, 6) 0.34829921005964853\n",
      "(0, 1, 4, 5) 0.3841420817883819\n",
      "(0, 1, 4, 6) 0.38059541082272014\n",
      "(0, 1, 5, 6) 0.32508463646622604\n",
      "(0, 2, 3, 4) 0.39545381267128804\n",
      "(0, 2, 3, 5) 0.344080821108066\n",
      "(0, 2, 3, 6) 0.3455317319576549\n",
      "(0, 2, 4, 5) 0.3789564189370735\n",
      "(0, 2, 4, 6) 0.3769681336987479\n",
      "(0, 2, 5, 6) 0.31613735289376105\n",
      "(0, 3, 4, 5) 0.41568595840722233\n",
      "(0, 3, 4, 6) 0.41316029878016014\n",
      "(0, 3, 5, 6) 0.33346767693051754\n",
      "(0, 4, 5, 6) 0.3934386587135257\n",
      "(1, 2, 3, 4) 0.392578859691547\n",
      "(1, 2, 3, 5) 0.3097157289483583\n",
      "(1, 2, 3, 6) 0.3132623999140201\n",
      "(1, 2, 4, 5) 0.37892955021763663\n",
      "(1, 2, 4, 6) 0.379037025095384\n",
      "(1, 2, 5, 6) 0.2867161051104304\n",
      "(1, 3, 4, 5) 0.40184856789725404\n",
      "(1, 3, 4, 6) 0.40141866838626467\n",
      "(1, 3, 5, 6) 0.2902359073566554\n",
      "(1, 4, 5, 6) 0.3845451125799344\n",
      "(2, 3, 4, 5) 0.3955344188295986\n",
      "(2, 3, 4, 6) 0.39666290504594554\n",
      "(2, 3, 5, 6) 0.2801601375678435\n",
      "(2, 4, 5, 6) 0.37360954376914396\n",
      "(3, 4, 5, 6) 0.3923370412166156\n",
      "5\n",
      "(0, 1, 2, 3, 4) 0.3766886990166049\n",
      "(0, 1, 2, 3, 5) 0.3351926487183621\n",
      "(0, 1, 2, 3, 6) 0.3362566500080606\n",
      "(0, 1, 2, 4, 5) 0.3645977752700306\n",
      "(0, 1, 2, 4, 6) 0.3635982589069805\n",
      "(0, 1, 2, 5, 6) 0.3164275350636788\n",
      "(0, 1, 3, 4, 5) 0.3889085926164759\n",
      "(0, 1, 3, 4, 6) 0.38758665162018374\n",
      "(0, 1, 3, 5, 6) 0.32909882315008865\n",
      "(0, 1, 4, 5, 6) 0.3735611800741577\n",
      "(0, 2, 3, 4, 5) 0.3859422859906497\n",
      "(0, 2, 3, 4, 6) 0.3855553764307593\n",
      "(0, 2, 3, 5, 6) 0.32387554409156855\n",
      "(0, 2, 4, 5, 6) 0.3678220216024504\n",
      "(0, 3, 4, 5, 6) 0.3896179268096082\n",
      "(1, 2, 3, 4, 5) 0.3757214251168789\n",
      "(1, 2, 3, 4, 6) 0.37659197162663227\n",
      "(1, 2, 3, 5, 6) 0.2960180557794615\n",
      "(1, 2, 4, 5, 6) 0.3605674673545059\n",
      "(1, 3, 4, 5, 6) 0.37407705948734477\n",
      "(2, 3, 4, 5, 6) 0.3676608092858294\n",
      "6\n",
      "(0, 1, 2, 3, 4, 5) 0.37117523778816697\n",
      "(0, 1, 2, 3, 4, 6) 0.3710462679348703\n",
      "(0, 1, 2, 3, 5, 6) 0.3228115428018701\n",
      "(0, 1, 2, 4, 5, 6) 0.35776237304530073\n",
      "(0, 1, 3, 4, 5, 6) 0.3738083722929766\n",
      "(0, 2, 3, 4, 5, 6) 0.3700789940351443\n",
      "(1, 2, 3, 4, 5, 6) 0.3584394647751088\n",
      "7\n",
      "(0, 1, 2, 3, 4, 5, 6) 0.3607317503819197\n"
     ]
    }
   ],
   "source": [
    "ens_sizes = np.arange(2, num_models + 1)\n",
    "for j, ens_size in enumerate(ens_sizes):\n",
    "    print(ens_size)\n",
    "    combinations = list(itertools.combinations(range(num_models), ens_size))\n",
    "    for comb in combinations:\n",
    "        val = 0\n",
    "        for i, pair in enumerate(list(itertools.combinations(comb, 2))):\n",
    "            val += stats_matrices[\"binary_disagreement\"].values[pair]\n",
    "        val = val / (i + 1)\n",
    "        print(comb, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
